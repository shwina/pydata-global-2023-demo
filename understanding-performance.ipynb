{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480e983e-4db7-48a6-8504-53babaa59f2d",
   "metadata": {},
   "source": [
    "# Improving performance ðŸ“ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1101dc-f02c-4392-8bd0-3c3fcb04528a",
   "metadata": {},
   "source": [
    "In this notebook, we'll see how to use the profiler to see what code ran on the GPU and what ran on the CPU. We'll see that rewriting code to keep everything on the GPU results in optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c18f3-ee3e-42c1-b8db-3f8127791c38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf6991-a335-4a91-ae4c-1b598795ed94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4601fd-70c6-4436-8783-9a083ef0ce10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame()  # warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1170e4b-7e54-4482-bf26-0407b055d82a",
   "metadata": {},
   "source": [
    "Let's generate some data and do some timeseries operations with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c72c10-76cd-421d-83c6-37c51a8d47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"10ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "data = data.iloc[rng.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7a358-676a-42ca-9e89-b34cfa5c9d13",
   "metadata": {},
   "source": [
    "That runs quite slowly, even when `cudf.pandas` is enabled. Notice what happens when you run the same code with the `%%cudf.pandas.profile` magic: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56a83c-1ae9-4c15-8551-ed7930e2a0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"10ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "data = data.iloc[rng.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23e97e-92a4-49eb-89bb-ec24d75e9f19",
   "metadata": {},
   "source": [
    "We get a report that shows what functions executed on the GPU, and what functions executed on the CPU. In the code above, everything executed on the GPU except for the `indexer_between_time` function, which is [not supported by the cuDF library](https://docs.rapids.ai/api/cudf/stable/user_guide/api_docs/). \n",
    "\n",
    "The key to getting great performance with `cudf.pandas` is to minimize the number of operations that fall back to CPU. While rarely, this cannot be avoided, it often can be achieved with simple rewrites of your code. Let's rewrite the code to use operations that _are_ supported by cuDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec86cec-6d27-4cc7-bd1b-512c0ac42354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"100ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "data = data.iloc[((rng.hour >= 9) & (rng.minute >= 30)) | (rng.hour <= 16)]\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53206947-0147-4963-8671-655c580af55f",
   "metadata": {},
   "source": [
    "Not only is this _much_ faster on the GPU, but it's also quite a bit faster on the CPU - a nice win-win!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
