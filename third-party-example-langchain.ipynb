{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "809bb667-db52-4a6f-83b9-f5a24bf0a8ba",
   "metadata": {},
   "source": [
    "# Third-party library example: cudf.pandas üöÄüêº + langchain ü¶úÔ∏èüîó!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19081ac-e86d-4688-8917-05d927392560",
   "metadata": {},
   "source": [
    "In this notebook, we'll demonstrate how `cudf.pandas` works with third-party libraries that depend on pandas.\n",
    "\n",
    "We'll load some data into a DataFrame and use [langchain's Pandas integration](https://python.langchain.com/docs/integrations/toolkits/pandas) to answer questions about that data. We'll see that even though langchain doesn't know anything about cuDF, it will still automagically use the GPU to answer those questions much faster than with regular pandas!\n",
    "\n",
    "‚ö†Ô∏è Note that at the time of writing, `langchain` is undergoing considerable changes (for example, see [here](https://github.com/langchain-ai/langchain/discussions/14243)). You may have to change some of the code in this notebook to make it work.\n",
    "\n",
    "üí∞‚ùó Here we're using OpenAI's `gpt-4` model with langchain ([setup instructions](https://python.langchain.com/docs/integrations/llms/openai)). Note that at the time of writing, you need to buy credits from OpenAI to use this model via API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0a5e36-9880-4e34-86d0-0e0cc2f85343",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99753e-2412-4c1a-b2b9-501308be9065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73e88a-9588-499b-9601-a428df084905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524aca2b-09fb-4914-a5fd-ca7bdf154fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b64ef9-4b6b-4e5f-8d1e-3008739584ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import download_taxi_data\n",
    "\n",
    "download_taxi_data(n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0303020-d0e9-4d8c-a5ab-f9980bb8eb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs = [\n",
    "    pd.read_parquet(\"yellow_tripdata_2021-{:02d}.parquet\".format(i))\n",
    "    for i in range(1, 13)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02772d-3cb1-4a26-b302-60ec1f572f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e0c1a-84af-4160-a2f4-cb21a7246b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad517e-850a-4212-b22e-fbe9ff0605da",
   "metadata": {
    "tags": []
   },
   "source": [
    "We're not going to use all the data, so let's filter out just the columns we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b45aee-5b80-4905-878d-53ae1066e34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[[\"VendorID\",\n",
    "         \"tpep_pickup_datetime\",\n",
    "         \"tpep_dropoff_datetime\",\n",
    "         \"passenger_count\",\n",
    "         \"tip_amount\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648d58b-7c8d-4949-bdcd-e1b316f88fbf",
   "metadata": {},
   "source": [
    "OK, now let's set up an agent that will let us ask questions about the data in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d4512-9ea4-4b6d-989a-a90462cf72ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    df,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5835b-6895-49f7-a5c7-e66e123fca72",
   "metadata": {},
   "source": [
    "Now, let's ask some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf4057-1b2b-49b8-b3f1-0be70433a23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = agent.run(\"How many rows are there?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58014e6f-2ea3-4de1-a6dc-61998329ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = agent.run(\"Which vendor received the most tips?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87069f0e-1295-4348-bd64-53019993775a",
   "metadata": {},
   "source": [
    "Now, let's ask a more complicated question. Note that this part is finicky - sometimes it can return a response that simply contains the code that _should_ be run, but doesn't actually run the code. You may have to try a few times before you can get a useful response. And because we're caching responses in the file `.langchain.db`, you have to delete that file each time you want to try to get a new response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23865eea-6198-480c-a2ff-c1af08efafb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "result = agent.run(\n",
    "    \"\"\"\n",
    "    Which 30-minute, 1-hour, 2-hour, 5-hour and 24-hour windows have the most trips?\n",
    "    Don't use any inplace operations please!\n",
    "    \"\"\"\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
