{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac1ffa25-b8c9-46c5-820b-f769684e08d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  8 08:53:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro GV100        Off  | 00000000:15:00.0 Off |                  Off |\n",
      "| 37%   50C    P2    42W / 250W |     10MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro GV100        Off  | 00000000:2D:00.0  On |                  Off |\n",
      "| 44%   58C    P0    45W / 250W |    777MiB / 32768MiB |     12%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       958      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A     12983      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A       958      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    1   N/A  N/A     12983      G   /usr/lib/xorg/Xorg                193MiB |\n",
      "|    1   N/A  N/A     13110      G   /usr/bin/gnome-shell              165MiB |\n",
      "|    1   N/A  N/A    740582      G   /usr/lib/firefox/firefox          272MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590899b6-3e3e-430c-8dda-e3233af617c2",
   "metadata": {},
   "source": [
    "## Part 1: Quick intro to cudf.pandas üöÄüêº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e4d86-803b-4d9a-8dc1-225e7b336b55",
   "metadata": {},
   "source": [
    "Comment this line in or out depending on whether you want to enable `cudf.pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f20164-b5da-4354-997f-b3b4da0a9566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f26e46-fc85-4cb6-b443-84c59093a062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757b30c-a09f-45d2-baa6-55063734fd2e",
   "metadata": {},
   "source": [
    "In this section, we're running some basic pandas functions with randomly generated data and timing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f59c30-3057-41ac-b2df-130fc71bd25a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STRINGS = [\"\".join(random.choices(\"abcdefg\", k=5)) for _ in range(1000)] + [None]    \n",
    "\n",
    "def make_df(size):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"id\": np.random.randint(low=0, high=100, size=size),\n",
    "            \"x\": np.random.rand(size),\n",
    "            \"y\": np.random.rand(size),\n",
    "            \"s\": random.choices(STRINGS, k=size)\n",
    "        }\n",
    "    )\n",
    "\n",
    "df1 = make_df(10_000_000)\n",
    "df2 = make_df(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ea1a3-54cf-44a5-b0fe-a9ae270d3589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df1.groupby(\"id\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd9d08-bceb-4081-ab63-7e0640fef5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df1[\"s\"].str.contains(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2ffaa-4cbd-4cfc-9083-9ddf1926661b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df1.merge(df2, on=[\"id\", \"s\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9a858-ce93-4e56-b0df-2674ee59a922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df1.count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bee12d-f939-4129-b822-1eaad18bc5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df1.count(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a373a85-5631-4408-a21b-f5e61074d0cd",
   "metadata": {},
   "source": [
    "### How does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af6e91-90e7-45b5-92f7-61ced884207f",
   "metadata": {},
   "source": [
    "When we did `%load_ext cudf.pandas`, we made it so that `import pandas` (or any submodules) imports a proxy module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2833e03-0a3b-47fd-94f9-148a6d40da43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58283c96-08db-4e8d-a394-c13ff2511a3c",
   "metadata": {},
   "source": [
    "That proxy module is composed of proxy functions, and proxy types containing proxy methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8945b-6a9c-448c-8afa-b04d261d97e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(pd.read_csv))\n",
    "print(type(pd.DataFrame))\n",
    "print(type(pd.DataFrame.max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44bedd-4ff9-4da8-b105-9d8b0cb64f97",
   "metadata": {},
   "source": [
    "Operations on proxy functions and methods dispatch to cuDF or pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42270df-a43e-4133-87b6-ecc441564e1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"how-cudf-pandas-works.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12226a1-dec7-4b76-8adf-03447d6e591d",
   "metadata": {},
   "source": [
    "### Why `.count(axis=1)` is slower when `cudf.pandas` is enabled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336ec54-e966-4304-ab7e-37882b56372b",
   "metadata": {},
   "source": [
    "As you can see from the diagram above, when an operation isn't supported by cuDF, we copy data from GPU to CPU and then use pandas for that operation. This copying can add signficant overhead (especially if the data is large)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e98494d-1474-4fdc-972f-60e30b9f6713",
   "metadata": {},
   "source": [
    "### Can we use `cudf.pandas` with other libraries?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c77ee37-154e-4863-b9cf-adde44eaa403",
   "metadata": {},
   "source": [
    "When `cudf.pandas` enabled, you can still pass DataFrames to other libraries and expect things to work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab3679-6e74-4334-bef0-62681c0f64ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=df2.x[::10], y=df2.y[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184f0c3-0834-4597-a52d-dc6f8a0a2dbf",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd407a-c4fc-48d7-ac7b-e208431377e1",
   "metadata": {},
   "source": [
    "Let's generate some data and do some timeseries operations with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26eeab-ba5f-45e6-9205-4a12e13462ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# generate some random timeseries data:\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"10ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "\n",
    "# filter the data to just between 9:30am and 4pm:\n",
    "data = data.iloc[rng.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "\n",
    "# get daily means:\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d4495-4846-448a-80f0-f1fba9435d50",
   "metadata": {},
   "source": [
    "That runs quite slowly, even when `cudf.pandas` is enabled. Notice what happens when you run the same code with the `%%cudf.pandas.profile` magic: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc15e6c-3cba-4b82-a591-f2854b2cd15b",
   "metadata": {},
   "source": [
    "### Using the profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c72c10-76cd-421d-83c6-37c51a8d47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cudf.pandas.profile\n",
    "\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"10ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "data = data.iloc[rng.indexer_between_time(\"09:30\", \"16:00\")]\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aee600-055f-4175-9df6-b2087c7eabc4",
   "metadata": {},
   "source": [
    "We get a report that shows what functions executed on the GPU, and what functions executed on the CPU. In the code above, everything executed on the GPU except for the `indexer_between_time` function, which is [not supported by the cuDF library](https://docs.rapids.ai/api/cudf/stable/user_guide/api_docs/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8dde2-e5e0-4efd-8843-17d61aecc3cb",
   "metadata": {},
   "source": [
    "### Optimizing our code for GPU execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9664f9-6161-482c-89dd-f6b7e3ac0f68",
   "metadata": {
    "tags": []
   },
   "source": [
    "The key to getting great performance with `cudf.pandas` is to minimize the number of operations that fall back to CPU. While rarely, this cannot be avoided, it often can be achieved with simple rewrites of your code. Let's rewrite the code to use operations that _are_ supported by cuDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec86cec-6d27-4cc7-bd1b-512c0ac42354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rng = pd.date_range(\"2023-01-01\", \"2023-02-01\", freq=\"100ms\")\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(len(rng)),\n",
    "        \"b\": np.random.rand(len(rng))\n",
    "    },\n",
    "    index=rng\n",
    ")\n",
    "\n",
    "# note: using datetime properties instead of `indexer_between_time`:\n",
    "data = data.iloc[((rng.hour >= 9) & (rng.minute >= 30)) | (rng.hour <= 16)]\n",
    "\n",
    "results = data.groupby(pd.Grouper(freq=\"1D\")).mean()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b1cce-69e6-496f-bfac-a535f7f30c09",
   "metadata": {},
   "source": [
    "Not only is this _much_ faster on the GPU, but it's also quite a bit faster on the CPU - a nice win-win!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b74036-3093-4f64-b228-3ad17ed6fbbd",
   "metadata": {},
   "source": [
    "## Part 3: third-party code acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845dff0-7112-4ecd-9308-d76e58e0afa2",
   "metadata": {},
   "source": [
    "In this section, we'll demonstrate how `cudf.pandas` works with third-party libraries that depend on pandas.\n",
    "\n",
    "We'll load some data into a DataFrame and use [langchain's Pandas integration](https://python.langchain.com/docs/integrations/toolkits/pandas) to answer questions about that data. We'll see that even though langchain doesn't know anything about cuDF, it will still automagically use the GPU to answer those questions much faster than with regular pandas!\n",
    "\n",
    "‚ö†Ô∏è Note that at the time of writing, `langchain` is undergoing considerable changes (for example, see [here](https://github.com/langchain-ai/langchain/discussions/14243)). You may have to change some of the code in this notebook to make it work.\n",
    "\n",
    "üí∞‚ùó Here we're using OpenAI's `gpt-4` model with langchain ([setup instructions](https://python.langchain.com/docs/integrations/llms/openai)). Note that at the time of writing, you need to buy credits from OpenAI to use this model via API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1203d-5f0e-4e56-969e-64ea89a26684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156e11a-a35a-4784-9874-23c765ba758a",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc23b8-1b0f-46ce-8b41-2db6fa2df749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_parquet(\"yellow_tripdata_2021-{:02d}.parquet\".format(i))\n",
    "        for i in range(1, 13)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = df[[\"VendorID\",\n",
    "         \"tpep_pickup_datetime\",\n",
    "         \"tpep_dropoff_datetime\",\n",
    "         \"passenger_count\",\n",
    "         \"tip_amount\"]]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b10bbd-93a4-4d56-bb2d-a27cb34d30cf",
   "metadata": {},
   "source": [
    "### Asking questions about our data (note: responses are cached!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a08fa4-4b39-452c-92e1-4eddd6382e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    df,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    handle_parsing_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46523bd2-ec99-4a5e-ba4d-64ef3634ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(agent.run(\"How many rows are there?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089538d2-1a26-4d3a-8dce-570e33f2f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(agent.run(\"Which vendor received the most tips?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385f017-3279-4761-abdf-af95de754a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\n",
    "    agent.run(\n",
    "        \"\"\"\n",
    "        Which 30-minute, 1-hour, 2-hour, 5-hour and 24-hour windows have the most trips?\n",
    "        Don't use any inplace operations please!\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56398e02-1e57-4787-afc5-11add1499ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
